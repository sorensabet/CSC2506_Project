import os import globimport torchimport randomimport shutilimport pypianorollimport numpy as npimport matplotlib.pyplot as pltfrom tqdm import tqdm from pathlib import Pathfrom pypianoroll import Multitrack, Track, BinaryTrackfrom livelossplot import PlotLosses from livelossplot.outputs import MatplotlibPlotn_tracks = 1n_pitches = 72lowest_pitch = 24n_samples_per_song = 8           # NEED TO FIGURE OUT WHAT THIS IS! n_measures = 16beat_resolution = 4              # NEED TO FIGURE OUT WHAT THIS IS! programs = [0]is_drums = [False]track_names = ['Piano']tempo = 120batch_size = 16latent_dim = 128n_steps = 20000# Samplingsample_interval = 10            # NEED TO FIGURE OUT WHAT THIS IS n_samples = 4                   # NEED TO FIGURE OUT WHAT THIS IS measure_resolution = 4 * beat_resolution tempo_array = np.full((4 * 4 * measure_resolution, 1), tempo)assert 24 % beat_resolution == 0, (    "beat_resolution must be a factor of 24 (the beat resolution used in "    "the source dataset).")assert len(programs) == len(is_drums) and len(programs) == len(track_names), (    "Lengths of programs, is_drums and track_names must be the same.")  # Using my own preprocessed data instead of the LPD dataset_root = "/Users/sorensabet/Desktop/Master's Coursework/CSC2506_Project/Splitting MIDI Files/"npz_files = glob.glob(dataset_root + '/**/*.npz', recursive=True)# for c,f in enumerate(npz_files):#     mt = pypianoroll.load(f)#     mt.set_resolution(24)    #     axs = mt.plot()#     plt.gcf().set_size_inches((16, 8))#     for ax in axs:#         for x in range(96, 12 * 96, 96):     #             ax.axvline(x - 0.5, color='k', linestyle='-', linewidth=1)#     plt.show()#     if (c > 10):#         breakdata = []count = 0for f in tqdm((npz_files)):    if (count > 100):        break    mt = pypianoroll.load(f)    mt.binarize()    mt.set_resolution(beat_resolution)        pianoroll = mt.tracks[0].pianoroll > 0    pianoroll = pianoroll[np.newaxis, ...]    pianoroll = pianoroll[:,:, lowest_pitch:lowest_pitch + n_pitches]    n_total_measures = mt.get_max_length()//measure_resolution    candidate = n_total_measures - n_measures    target_n_samples = min(n_total_measures//n_measures, n_samples_per_song)        # CHANGE TRUE TO FALSE AFTERWARDS!    for idx in np.random.choice(candidate, target_n_samples, True):        start = idx * measure_resolution         end = (idx + n_measures) * measure_resolution                 if (pianoroll.sum(axis=(1,2)) < 10).any():            continue                 if pianoroll[:, start:end].shape[1] == 64 and pianoroll[:, start:end].shape[2] == 72:            data.append(pianoroll[:, start:end])        print(n_total_measures)    count += 1    random.shuffle(data)data = np.stack(data)print(f"Successfully collect {len(data)} samples from {len(npz_files)} songs")print(f"Data shape : {data.shape}")# Visualizing examples of training samples tracks = []for idx, (program, is_drum, track_name) in enumerate(zip(programs, is_drums, track_names)):    pianoroll = np.pad(        np.concatenate(data[:4], 1)[idx], ((0, 0), (lowest_pitch, 128 - lowest_pitch - n_pitches)))    tracks.append(Track(name=track_name, program=program, is_drum=is_drum, pianoroll=pianoroll))multitrack = Multitrack(tracks=tracks, tempo=tempo_array, resolution=beat_resolution)axs = multitrack.plot()plt.gcf().set_size_inches((18,8))for ax in axs:     for x in range(measure_resolution, 4 * 4 * measure_resolution, measure_resolution):        if x % (measure_resolution * 4) == 0:            ax.axvline(x - 0.5, color='k')        else:            ax.axvline(x - 0.5, color='k', linestyle='-', linewidth=1)plt.show()# Creating dataset and dataloader data = torch.as_tensor(data, dtype=torch.float32)dataset = torch.utils.data.TensorDataset(data)data_loader = torch.utils.data.DataLoader(    dataset, batch_size=batch_size, drop_last=True, shuffle=True)# Defining the generator class GeneratorBlock(torch.nn.Module):    def __init__(self, in_dim, out_dim, kernel, stride):        super().__init__()        self.transconv(torch.nn.ConvTranspose3d(in_dim, out_dim, kernel, stride))        self.batchnorm = torch.nn.BatchNorm3d(out_dim)            def forward(self, x):        x = self.transconv(x)        x = self.batchnorm(x)        return torch.nn.functional.relu(x)    class Generator(torch.nn.Module):    def __init__(self):        super().__init__()        self.transconv0 = GeneratorBlock(latent_dim, 256, (4, 1, 1), (4, 1, 1))        self.transconv1 = GeneratorBlock(256, 128, (1, 4, 1), (1, 4, 1))        self.transconv2 = GeneratorBlock(128, 64, (1, 1, 4), (1, 1, 4))        self.transconv3 = GeneratorBlock(64, 32, (1, 1, 3), (1, 1, 1))        self.transconv4 = torch.nn.ModuleList([            GeneratorBlock(32, 16, (1, 4, 1), (1, 4, 1))            for _ in range(n_tracks)        ])        self.transconv5 = torch.nn.ModuleList([            GeneratorBlock(16, 1, (1, 1, 12), (1, 1, 12))            for _ in range(n_tracks)        ])            def forward(self, x):         x = x.view(-1, latent_dim, 1, 1, 1)        x = self.transconv0(x)        x = self.transconv1(x)        x = self.transconv2(x)        x = self.transconv3(x)        x = [transconv(x) for transconv in self.transconv4]        x = torch.cat([transconv(x_) for x_, transconv in zip(x, self.transconv5)], 1)        x = x.view(-1, n_tracks, n_measures * measure_resolution, n_pitches)        return x# Defining the discriminator class LayerNorm(torch.nn.Module):    def __init__(self, n_features, eps=1e-5, affine=True):        super().__init__()        self.n_features = n_features        self.affine = affine         self.eps = eps        if self.affine:            self.gamma = torch.nn.Parameter(torch.Tensor(n_features).uniform_())            self.beta = torch.nn.Parameter(torch.zeros(n_features))        def forward(self, x):        shape = [-1] + [1] * (x.dim() - 1)                # Reshape to batch size x everything else and take the mean over everything else         # Basically norm over everything but batch (layernorm)        # The last view unrolls it back to original shape         mean = x.view(x.size(0), -1).mean(1).view(*shape)        std = x.view(x.size(0), -1).std(1).view(*shape)        y = (x - mean)/(std + self.eps)        if self.affine:            shape = [1,-1] + [1]*(x.dim() - 2)            y = self.gamma.view(*shape) * y + self.beta.view(*shape)        return y     class DiscriminatorBlock(torch.nn.Module):    def __init__(self, in_dim, out_dim, kernel, stride):        super().__init__()        self.transconv = torch.nn.Conv3d(in_dim, out_dim. kernel, stride)        self.layernorm = LayerNorm(out_dim)        def forward(self, x):        x = self.transconv(x)        x = self.layernorm(x)        return torch.nn.functional.leaky_relu(x)class Discriminator(torch.nn.Module):    """ A CNN based discriminator. Takes input either a real sample or fake sample and outputs scaler indicating authenticity"""        def __init__(self):        super().__init__()        self.conv0 = torch.nn.ModuleList([            DiscriminatorBlock(1, 16, (1, 1, 12), (1, 1, 12)) for _ in range(n_tracks)            ])        self.conv1 = torch.nn.ModuleList([            DiscriminatorBlock(16, 16, (1, 4, 1), (1, 4, 1)) for _ in range(n_tracks)            ])                ## Change from 16*5 to 16*n_tracks         self.conv2 = DiscriminatorBlock(16*n_tracks, 64, (1, 1, 3), (1, 1, 1))        self.conv3 = DiscriminatorBlock(64, 64, (1, 1, 4), (1, 1, 4))        self.conv4 = DiscriminatorBlock(64, 128, (1, 4, 1), (1, 4, 1))        self.conv5 = DiscriminatorBlock(128, 128, (2, 1, 1), (1, 1, 1))        self.conv6 = DiscriminatorBlock(128, 256, (3, 1, 1), (3, 1, 1))        self.dense = torch.nn.Linear(256, 1)            def forward(self, x):        x = x.view(-1, n_tracks, n_measures, measure_resolution, n_pitches)        x = [conv(x[:,[i]]) for i, conv in enumerate(self.conv0)]                # Concatenate along track dimension. Each track went from C=1 -> C=16        # so in self.conv2 the input channel is 16*n_tracks         x = torch.cat([conv(x_) for x_, conv in zip(x, self.conv1)],1)        x = self.conv2(x)        x = self.conv3(x)        x = self.conv4(x)        x = self.conv5(x)        x = self.conv6(x)        x = x.view(-1, 256)        x = self.dense(x)        return x # Training functions def compute_gradient_penalty(discriminator, real_samples, fake_samples):    """ Compute gradient penalty for regularization """     # Get random interpolations between real and fake samples     alpha = torch.rand(real_samples.size(0), 1, 1, 1).cuda()    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples))    interpolates = interpolates.requires_grad_(True)        #Get discriminator output for interpolations     d_interpolates = discriminator(interpolates)        # Get gradients w.r.t. the interpolations     fake = torch.ones(real_samples.size(0), 1).cuda()    gradients = torch.autograd.grad(        outputs = d_interpolates,        inputs = interpolates,         grad_outputs=fake,         create_graph=True,         retain_graph=True,         only_inputs=True)[0]        # Compute gradients penalty     gradients = gradients.view(gradients.size(0), -1)    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()    return gradient_penalty def train_one_step(d_optimizer, g_optimizer, real_samples):    """ Train the networks for one step. """    # Sample from the latent distribution     latent = torch.randn(batch_size, latent_dim)        # Transfer data to GPU     if torch.cuda.is_available():         real_samples = real_samples.cuda()         latent = latent.cuda()         # === Train the discriminator ===    # Reset chaced gradients to zero     d_optimizer.zero_grad()        # Get discriminator outputs for the real samples     prediction_real = discriminator(real_samples)    d_loss_real = -torch.mean(prediction_real) # Wnat discriminator to predict ls for real sample -> minimize negative of it    # Backprop the gradients     d_loss_real.backward()         # Generate fake samples with the generator     fake_samples = generator(latent)    # Get discriminator outputs for the fake samples     prediction_fake_d = discriminator(fake_samples.detach())        # Compute the loss function     d_loss_fake = torch.mean(prediction_fake_d)        # Backpropagate the gradients     d_loss_fake.backward()         # Compute gradient penalty     gradient_penalty = 10.0 * compute_gradient_penalty(        discriminator, real_samples.data, fake_samples.data)    # Backpropagate the gradients     gradient_penalty.backward()         # Update the weights     d_optimizer.step()         # === Train the generator ===    # Reset cached gradients to zero     g_optimizer.zero_grad()         # Get discriminator outputs for the fake samples     prediction_fake_g = discriminator(fake_samples)        # Compute the loss function     g_loss = -torch.mean(prediction_fake_g) # generator wants discriminator to think its samples are all ls (real samples)        # Backpropagate the gradients    g_loss.backward()         # Update the weights     g_optimizer.step()     return d_loss_real + d_loss_fake, g_loss# Training preparation # Create data loader data_loader = get_data_loader() # Create neural networks discriminator = Discriminator()generator = Generator() print("Number of parameters in G: {}".format(    sum(p.numel() for p in generator.parameters() if p.requires_grad)))print('Number of parameters in D: {}'.format(    sum(p.numel() for p in discriminator.parameters() if p.requires_grad)))# Create optimizers d_optimizer = torch.optim.Adam(    discriminator.parameters(), lr=0.001, betas=(0.5, 0.9))g_optimizer = torch.optim.Adam(    generator.parameters(), lr=0.001, betas=(0.5, 0.9))# Prepare inputs for the sampler, which will run during the training sample_latent = torch.randn(n_samples, latent_dim)# Transfer the neural nets and samples to GPU if torch.cuda.is_available():     discriminator = discriminator.cuda()    generator = generator.cuda()     sample_latent = sample_latent.cuda() # Create an empty dictionary to store history samples history_samples = {} # Create a LiveLoss logger instance for monitoring liveloss = PlotLosses(outputs=[MatplotlibPlot(cell_size=(6,2))])### TRAINING # Initialize step step = 0# Create progress bar for instance monitoring progress_bar = tqdm(total=n_steps, initial=step, ncols=80, mininterval=1)# Start iterations while step < n_steps + 1:     # Iterate over the dataset     for real_samples in data_loader:         # Train the NN         generator.train()         d_loss, g_loss = train_one_step(d_optimizer, g_optimizer, real_samples[0])                # Record smoothened loss values to LiveLoss logger         if step > 0:             running_d_loss = 0.05 * d_loss + 0.95 * running_d_loss            running_g_loss = 0.05 * g_loss + 0.95 * running_g_loss         else:            running_d_loss, running_g_loss = 0.0, 0.0     liveloss.update({'negative_critic_loss': -running_d_loss})        # Update losses to progress bar    progress_bar.set_description_str(        "(d_loss={: 8.6f}, g_loss={: 8.6f})".format(d_loss, g_loss))        if step % sample_interval == 0:        # Get generated samples         generator.eval()        samples = generator(sample_latent).cpu().detach().numpy()        history_samples[step] = samples         # Display loss curves        clear_output(True)        if step > 0:             liveloss.send()                 # Display generated samples         samples = samples.transpose(1, 0, 2, 3).reshape(n_tracks, -1, n_pitches)        tracks = []         for idx, (program, is_drum, track_name) in enumerate(                zip(programs, is_drums, track_names)        ):            pianoroll = np.pad(                    samples[idx] > 0.5,                    ((0,0), (lowest_pitch, 128 - lowest_pitch - n_pitches))                )            tracks.append(                Track(                    name=track_name,                    program=program,                    is_drum=is_drum,                     pianoroll=pianoroll                    )                )            m = Multitrack(                tracks=tracks,                 tempo=tempo_array,                 resolution=beat_resolution,             )                        axs = m.plot()             plt.gcf().set_size_inces((16, 8))            for ax in axs:                 for x in range(                        measure_resolution,                         4 * measure_resolution * n_measures,                         measure_resolution):                     if x % (measure_resolution * 4) == 0:                         ax.axvline(x - 0.5, color='k')                    else:                        ax.axvline(x - 0.5, color='k', linestyle='-', linewidth=1)            plt.show()                     step += 1,         progress_bar.update(1)        if step >= n_steps:            break ### TRAINING HISTORY steps = [0, sample_interval, 10 * sample_interval, 100*sample_interval, n_steps]for step in steps:     print(f"step={step}")    samples = history_samples[step].transpose(1, 0, 2, 3).reshape(n_tracks, -1, n_pitches)    print(history_samples[step].shape)    tracks = []    for idx, (program, is_drum, track_name) in enumerate(zip(programs, is_drums, track_names)):        pianoroll = np.pad(            samples[idx] > 0.5,            ((0,0), (lowest_pitch, 128-lowest_pitch-n_pitches))        )        tracks.append(            Track(                name=track_name,                 program=program,                 is_drum=is_drum,                 pianoroll=pianoroll,            )        )            m = Multitrack(tracks=tracks, tempo=tempo_array, resolution=beat_resolution)    axs = m.plot()    for ax in axs:         for x in range(                measure_resolution,                 4 * measure_resolution * n_measures,                 measure_resolution            ):             if (x % (measure_resolution * 4) == 0):                ax.axvline(x - 0.5, color='k')            else:                ax.axvline(x - 0.5, color='k', linestype='-', linewidth=1)        plt.gcf().set_size_inches((16, 8))        plt.show()     ### Save Modelstorch.save(discriminator.state_dict(), "discriminator.model")torch.save(generator.state_dict(), "generator.model")### Load Model discriminator = Discriminator() generator = Generator()discriminator.load_state_dict(torch.load("discriminator.model"))generator.load_state_dict(torch.load("generator.model"))discriminator.cuda()generator.cuda() ### Use generator to generate random music## sample latent noise vector sample_latent = torch.randn(n_samples, latent_dim).cuda() ## Pass noise through generator output = generator(sample_latent)output = output.cpu().detach().numpy() ## Reshape it from a 4D tensor to a 3D tensor output = output.transpose(1, 0, 2, 3).reshape(n_tracks, -1, n_pitches)## Conver GAN output to a Multitrack that can be saved to midi using pypianorolltracks = []pianoroll = np.pad(    output[0] > 0.5,     ((0, 0), (lowest_pitch, 128 - lowest_pitch - n_pitches))    )track_name = "Piano"        program = 0is_drum = False tracks.append(    BinaryTrack(        name=track_name,        program=program,         is_drum=is_drum,        pianoroll=pianoroll,        )    )m = Multitrack(tracks=tracks, tempo=tempo_array, resolution=beat_resolution)pypianoroll.write('test.mid', m)                            